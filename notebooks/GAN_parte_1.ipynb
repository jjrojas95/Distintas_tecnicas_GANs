{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Generativas Adversarias\n",
    "Alrededor de la mitad del año 2014 algunos de los investigadores asociados al departamento de informática de la Universidad de Montreal proponen un nuevo marco de referencia para la estimación de un modelo Generativo basado en redes neuronales, el cual presentarón en el artículo por el que posteriormente le dará el nombre a este marco llamado [Generative Adversarial Network](https://arxiv.org/pdf/1406.2661.pdf) *Goodfellow et al* o GAN por sus siglas en inglés como se les conoce popularmente, pero antes que nada se hace necesario responder si quiera brevemente las siguientes cuestiones ¿Qué son los modelos generativos? ¿Qué sosn los procesos adversarios?\n",
    "\n",
    "De acuerdo con [developers google](https://developers.google.com/) un [modelo generativo](https://developers.google.com/machine-learning/gan/generative) tiene la capacidad de capturar la probabilidad conjunta P(X,Y) de un grupo de datos lo que le permite en algunos casos crear objetos similares a dicho conjunto. Por otro lado, un proceso adversario en su forma mas simple entrena dos modelos, que para el caso específico de las GAN's son llamados `G` y `D`, donde después de un tiempo de optimización **minimax** el entrenamiento tiende a estabilizar haciendo que ambos modelos no aprendan mas el uno del otro *Goodfellow et al* .\n",
    "\n",
    "El marco de referencia propuesto por *Goodfellow et al* consiste en dos redes neuronales: `G` como se le llama al modelo Generativo y `D` que se refiere a un modelo de clasificación que tratará de identificar que imagnes provienen del conjunto de datos real y cuales vienen de G, a este clsificador se le es llamado Modelo Discriminativo *Goodfellow et al*. Posteriormente de definir la arquitectura de ambos, se opta por entrenar ambos con dos objetivos contrarios: Por parte de `G` se tratará de **maximizar** la probabilodad de que `D` se equivoque. Opuesto, `D` buscará **minimizará** la probabilidada de caer en dicho error. Después de una amplia cantidad de epochs el proceso de aprendizaje se estabilizará. De acuerdo con las estimaciones de los autores el **punto óptimo** de `D` se acercará a un valor constante de $\\frac{1}{2}$. Se propone usar modelos de redes neuronales debido a el amplio y fácil uso del método de obtimización basado en backpropagation.\n",
    "\n",
    "## Detalles del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
