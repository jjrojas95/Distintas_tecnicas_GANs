{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Generativas Adversarias\n",
    "Alrededor de la mitad del año 2014 algunos de los investigadores asociados al departamento de informática de la Universidad de Montreal proponen un nuevo marco de referencia para la estimación de un modelo Generativo basado en redes neuronales, el cual presentarón en el artículo que posteriormente otorgaría el nombre de este marco de referencia hasta el día de hoy llamado [Generative Adversarial Network](https://arxiv.org/pdf/1406.2661.pdf) *Goodfellow et al* o GAN, por sus siglas en inglés, como se les conoce popularmente. Pero antes que nada se hace necesario responder si quiera brevemente las siguientes cuestiones ¿Qué son los modelos generativos? ¿Qué son los procesos adversarios?\n",
    "\n",
    "De acuerdo con [developers google](https://developers.google.com/) un [modelo generativo](https://developers.google.com/machine-learning/gan/generative) tiene la capacidad de capturar la probabilidad conjunta P(X,Y) o la densidad de probabilidad P(X) de un grupo de datos, lo que le permite en algunos casos crear objetos similares a dicho conjunto. Por otro lado, un proceso adversario en su forma mas simple es el procedimiento para entrenar dos modelos, para el caso específico de las GAN's son llamados `G` y `D`, a través de un proceso de optimización de juego **minimax**, donde después de un tiempo el entrenamiento se tiende a estabilizar causando que ambos modelos no aprendan mas el uno del otro *Goodfellow et al* .\n",
    "\n",
    "El marco de referencia propuesto por *Goodfellow et al* consiste en dos redes neuronales: `G` como se le llama al modelo Generativo y `D` que se refiere a un modelo de clasificación que tratará de identificar que imagnes provienen del conjunto de datos real y cuales vienen de `G`. A este clasificador se le es llamado Modelo Discriminativo *Goodfellow et al*. Posteriormente de definir la arquitectura de ambos, se opta por entrenarlos con dos objetivos contrarios: Por parte de `G` se tratará de **maximizar** la probabilidad de que `D` se equivoque. Por otro lado, `D` buscará **minimizar** la probabilidad de caer en dicho error. Después de un amplio entrenamiento proceso de aprendizaje se estabilizará. De acuerdo con las estimaciones de los autores el **punto** donde no existes mas aprendizaje es cuando `D` se acercará a un valor constante de $\\frac{1}{2}$. Se propone usar modelos de redes neuronales debido a el amplio y fácil uso del método de optimización basado en backpropagation.\n",
    "\n",
    "De lo descrito por *Goodfellow et al* en su [artículo](https://arxiv.org/pdf/1406.2661.pdf) me gustaría extraer un fragmento con el que trata de explicar de manera ilustrativa el proceso adversario que existen en este framework que proponen: \"El modelo generativo puede ser pensado de manera análoga como un equipo de falsificadores tratando de producir modena falsa los cuales la usan sin detección, por otro lado el modelo discriminativo es análogo a la policía que trata de detectar las falsificaciones. La competencia en este juego lleva a ambos equipos a mejorar en su tarea hasta que las falsificaciones de dinero son indetectables de los genuinos\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detalles del entrenamiento\n",
    "Este proceso inicia con la creación de un vector de ruido denotado por `z` que en algunas ocasiones es llamado *latent vector*. La creación de este vector obedece a una distribución de porbabilidad $p_z(z)$, donde en la mayoría de los casos es una distribución uniforme o Normal. \n",
    "\n",
    "Después se representa un mapeo al espacio de datos con $G(z; \\theta_g)$, donde la función `G` es diferenciable y es una red neuronal cuyos pesos pertenecen al conjunto $\\theta_g$. En paralelo también se define una función `D` diferenciable en forma de una red neuronal, cuyo mapeo de entrada es definido por $D(x; \\theta_d)$ donde su salida es un escalar que **refleja** la probabilidad de que `x` provenga del conjunto de datos reales en lugar de $p_g$ (distribución de los datos generados). El modelo final puede ser visto de la siguiente manera:\n",
    "\n",
    "![Diagrama DCGAN cortesía de developers google](https://developers.google.com/machine-learning/gan/images/gan_diagram.svg)\n",
    "\n",
    "Los autores defienen los siguientes creterios de optimización y suposiciones: \n",
    "* **Criterio de optimización**: Entrenar `D` para maximizar la probabilidad de que los valores que provengan del dataset sean asignados con la etiqueta binaria 1, mientras que los que provengan de la distribución $p_g$ sean asignados con 0. \n",
    "* **Criterio de optimización***: Se entrenará `G` para que `D` asigne $p_g$ como 1.\n",
    "* **Suposición**: El aprendizaje del generardor podrá ser efectivamente direccionado si el discriminador del que aprende se encuentra en su optimo global, es decir:$$D_G^*(x) = \\frac{p_{data}(x)}{p_{data}(x) + p_G(x)}$$ Lo que implica que en ocaciones se deba enternar el Discriminador múltiples veces antes de entrenar el generador.\n",
    "\n",
    "De acuerdo con *Goodfellow et all* la forma matemática de este problema es la siguiente:\n",
    "\n",
    "$$\n",
    "min_G~max_D~V(D, G) = \\mathbf{E}_{x \\sim p_{data}(x)}(logD(x)) + \\mathbf{E}_{z \\sim p_{z}(z)}(log(1 - D(G(z)))) \\tag{1}\n",
    "$$\n",
    "\n",
    "Para un mejor entendimiento, recorramos la ecuación parte por parte:\n",
    "* Lo referente a $\\mathbf{E}_{x \\sim p_{data}(x)}(...)$ tiene varias partes: $\\mathbf{E}$ es el valor esperado o promedio y $x \\sim p_{data}(x)$ especifíca el conjunto al que se va a evaluar su promedio, que para este caso vienen siendo todos los datos provenientes de los originales.\n",
    "* Con respecto a $\\mathbf{E}_{z \\sim p_{z}(z)}(...)$ Las partes funcionan de igual manera que en el anterior, un único distinto es que este apartado $z \\sim p_{z}(z)$ especifica que el conjunto obetivo es `z` en este caso.\n",
    "\n",
    "La figura 1 de *Goodfellow et al* ilustra de gran manera este proceso:\n",
    "![Proceso de entrenamiento de GAN obtenido de Goodfellow et al](../imagenes/figura_1_Goodfellow_GAN.PNG)\n",
    "\n",
    "Explicando el código de colores y líneas: \n",
    "1. La línea punteada azul corresponde al valor escalar de `D` en el espacio de datos.\n",
    "2. La línea de puntos negra corresponde al valor de la función de densidad de probabilidad de los datos reales en el dominio definido en la gráfica. **Esta es la distribución que queremos imitar con nuestro modelo generativo**.\n",
    "3. La linea continua verde correponde la función de densidad probabilidad de las imágenes generadas en ese instante de tiempo por `G`.\n",
    "4. La línea horizontal `x` es el espacio de datos completo.\n",
    "5. Las líneas continuas negras que van de la línea horizontal marcada como`z` a la líena horizontal `x` corresponde al mapeo realizado por $G(z)$ en el espacio de datos.\n",
    "\n",
    "En el instante de tiempo $(a)$ podemos asumir que las dos distribuciones (las generadas y las originales) son cercanas y `D` es un clasificador acercandose a su punto óptimo.\n",
    "\n",
    "En el instante de tiempo $(b)$ el discriminador `D` llega a su punto optimo, y por medio del aprendizaje de G este se acerca aún mas a la distribución deseada.\n",
    "\n",
    "En el instante de tiempo $(c)$ el gradiente porvisto por el discriminador `D` va guiando de mejor manera los pesos de `G` para que este pueda mapear eficazmente el *latent vector* con el espacio de datos donde es mas probable encontrar los datos originales.\n",
    "\n",
    "Por último, en el instante de tiempo $(d)$ el discriminador no puede direccionar mas el gradiente de `G` ya que las dos distribuciones son iguales, lo que hace `D` no pueda identificar la diferencia. Así su valor a partir de este punto siempre será $\\frac{1}{2}$\n",
    "\n",
    "Como vimos en la figura de propositos pedagógicos anterior, `D` es una parte crucial del problema debido a que debe porder diferenciar complemetamente entre los datos reales y los generados, ya que es computacionalmente prohibitivo. Se trará de que `D` sea completamente entrenado antes de que lo haga `G`, para esto se crea un nuevo hiperparámetro denotado como $k$ el cual es la cantidad de pasos de optimización que el algoritmo hace sobre `D` antes de hacer un paso en `G`. El buen ajuste de $k$ causará que `D` se aproxime al punto óptimo y hace que `G` cambie lo suficientemente lento. *Goodfellow et al* presentan el algoritmo en la siguiente imagen.\n",
    "\n",
    "![Algoritmo de entrenamiento GAN obtenido de Goodfellow et al](../imagenes/Algoritmo_entrenamiento_GAN.PNG)\n",
    "\n",
    "De acuerdo con *Goodfellow et al* la ecuación $(1)$ en ocaciones no provee suficiente gradiente para que `G` aprende, esto sobre todo en el principio del entrenamiento. Según los autores `D` puede rechazar los ejemplos que tengan alta confiabilidad de resultado, es decir, al principio para `D` es muy claro que los ejemplo generados con muy disntintos a los reales. **Así que en lugar de netrenar a `G` para minimizar $log(1- D(G(z)))$ trate de maximizar $logD(G(z))$**. Esto eventualmente nos llevará al mismo punto de entrenamiento sin embargo `D` proverá un mejor gradiente para `G`.\n",
    "\n",
    "A continuación, tataremos de imitar de la mejor manera la arquitectura para una GAN usando los conjuntos de datos MNIST y CIFAR-10:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurando nuestro entorno\n",
    "Lo primero que necesitamos es llamar las librerías, funciones y conjuntos de datos necesarios para realizar la tarea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from helper_func.custom_layers import Maxout\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.train import Checkpoint, CheckpointManager\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 777\n",
    "M = 50000\n",
    "LATENT_SIZE = 100\n",
    "LEARNING_RATE = .1\n",
    "BATCH_SIZE = 100\n",
    "BUFFER = 1000\n",
    "INIT_MOMENTUM = .5\n",
    "EPOCHS = 231\n",
    "K = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos, para esto vamos a usar el conjunto de números escritos a mano, popularmente llamado [MNIST](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist, mnist_test = tfds.load('mnist', split=['train[:50000]', 'train[50000:]'], data_dir='./', as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos los primeros 20 elementos de nuestro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = mnist.take(20)\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "for i, x in enumerate(tfds.as_numpy(sample)):\n",
    "    image, _ = x\n",
    "    ax = fig.add_subplot(4, 5, i+1)\n",
    "    ax.imshow(image[:, :, 0], cmap='gray')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adecuando el conjunto de datos\n",
    "En este apartado adecuaremos el dataset para que sea entrada del Discriminator. También debemos hallar el valor inicial del bias de la última capa del generador como lo hacen los autores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_img(image, label):\n",
    "    return tf.keras.backend.flatten(tf.cast(image, tf.float32)/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = mnist.map(\n",
    "    norm_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dataset = mnist.reduce(np.float32(0), lambda x,y: x/float(M) + y).numpy()\n",
    "mean_dataset = np.clip(mean_dataset, 1e-7, 1-1e-7)\n",
    "init_last_bias_gen = tf.convert_to_tensor(np.log(mean_dataset / (1. - mean_dataset)), dtype= tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = mnist_test.map(norm_img, num_parallel_calls=tf.data.experimental.AUTOTUNE).shuffle(3000).batch(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = mnist.shuffle(BUFFER)\n",
    "mnist = mnist.batch(BATCH_SIZE)\n",
    "mnist = mnist.cache()\n",
    "mnist = mnist.repeat()\n",
    "mnist = mnist.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = iter(mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Construcción de modelos\n",
    "Construimos nuestro **Generator** y **Discriminator** la GAN basada en en conjunto de datos MNIST. La arquitectura desarrollada por el investigador la puede encontrar [aqui](https://github.com/goodfeli/adversarial/blob/master/mnist.yaml):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "Como se dijo el **Generator** es un modelo basado en redes neuronales encargado de aprender la distribución del conjunto de datos real a partir del proceso adversario. Por otra parte, su entrada corresponde a un \"latent vector\" $z$ el cual tiene una distriución de probabilidad $p_z$ asociada. En este caso el autor elige en vector $z \\in \\mathbb{R}^{100}$ y $p_z = U(-\\sqrt{3}, \\sqrt{3})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator():\n",
    "    # Los autores hacen una serie de inicializaciones de pesos que se replicarán\n",
    "    init_kernel_gen = tf.random_uniform_initializer(-.05 , .05, seed=SEED)\n",
    "    model = Sequential([\n",
    "        Dense(1200, activation='relu', kernel_initializer=init_kernel_gen, input_shape=(100,)),\n",
    "        Dense(1200, activation='relu', kernel_initializer=init_kernel_gen),\n",
    "        Dense(784, activation='sigmoid', kernel_initializer=init_kernel_gen)\n",
    "    ])\n",
    "    \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = make_generator()\n",
    "gen.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos la inicialización del bias de la última capa del **Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = gen.trainable_variables[-1].assign(init_last_bias_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = make_generator()\n",
    "noise = tf.random.uniform([1, 100], minval=-1.*sqrt(3.), maxval=sqrt(3.), seed=SEED)\n",
    "generated_image = gen(noise, training=False)\n",
    "generated_image = tf.reshape(generated_image, (28, 28))\n",
    "plt.imshow(generated_image.numpy(), cmap='gray')\n",
    "_ = plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "El **discriminator**, al igual que generator es un modelo basado en redes neuronales. Su función es definir si una entrada es similar o no al conjunto real. Los autores implementan la capa [Maxout](https://arxiv.org/pdf/1302.4389.pdf) propuesta por *Goodfellow et al*, la cual (en una descripción breve) obtiene el máximo de una serie de combinaciones lineales de las entradas y es que para ellos explota de mejor manera las características de la técnica *Dropout*, para mayor información remitace al artículo en el link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator():\n",
    "    # El autor hace una serie de inicializaciones de pesos que se replicarán\n",
    "    init_kernel = tf.random_uniform_initializer(-.005 , .005, seed=SEED)\n",
    "    model = Sequential([\n",
    "        Maxout(240, 5, kernel_initializer=init_kernel, input_shape=(784,)),\n",
    "        Dropout(.2, seed=SEED),\n",
    "        Maxout(240, 5, kernel_initializer=init_kernel),\n",
    "        Dropout(.5, seed=SEED),\n",
    "        Dense(1, activation='sigmoid', kernel_initializer=init_kernel),\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = make_discriminator()\n",
    "disc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = make_discriminator()\n",
    "decision = disc(tf.reshape(generated_image, (1, -1)))\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la métrica de evaluación\n",
    "Siempre es bueno tener alguna métrica que nos pueda direccionar nuestro entrenamiento. En este caso ya que trabajamos con un problema no supervisado, es difícil encontrar alguna, sin embargo los autores eligen el la métrica **log likelihood** a través de una ventana Gaussiana de Parzen, esto con el fin de estimar la probabilidad que los datos de testeo se encuentren en la distribución $p_g$, para mayor información buscar leer el siguiente [artículo](http://proceedings.mlr.press/v9/desjardins10a/desjardins10a.pdf). Debido a que el calculo es muy intensivo nos limitaremos a probar 1000 muestras generadas. Para el caso del Dataset MNIST los autores definen $\\sigma = 0.2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parzen(data, samples, sigma):\n",
    "    x = data[:, None, :]\n",
    "    s = samples[None, :, :]\n",
    "    fracc = -.5 * ((x - s)/sigma)**2\n",
    "    exp_gaus = tf.reduce_sum(fracc, axis=-1)\n",
    "    \n",
    "    max_ = tf.reduce_max(exp_gaus, axis = -1)\n",
    "    \n",
    "    E = max_ + tf.math.log(tf.reduce_mean(tf.math.exp(exp_gaus - max_[:, None]), axis=-1))\n",
    "    Z = samples.shape[1] * tf.math.log(sigma * tf.math.sqrt(np.pi * 2))\n",
    "    \n",
    "    return tf.reduce_mean(E - Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ll_metric(test):\n",
    "    noise = tf.random.uniform((200, 100), minval=-1.*sqrt(3.), maxval=sqrt(3.), seed=SEED)\n",
    "    S = gen(noise, training=False)\n",
    "    ll = []\n",
    "    for test_batch in tqdm(mnist_test, desc='Log-likelihood Valid', leave=False):\n",
    "        ll.append(parzen(test_batch, S, .2).numpy())\n",
    "    ll = np.array(ll)\n",
    "    return ll.mean(), ll.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_metric(mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición funciones de costo y optimizadores\n",
    "En este apartado se definirán las funciones de costo para la actualización de las variables del **Discriminator** y la función del costos del **Generator**. Además se especificará los optimizadores de para el **Generator** y **Discriminator** con la respectiva programación de la tasa de aprendizaje y momentum. Empezaremos por estos últimos:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forma de disminución de tasa de aprendizaje usada por los autores\n",
    "class ExponentialDecayGANPaper(LearningRateSchedule):\n",
    "    \n",
    "    def __init__(self, init_lr=.1, decay_factor = 1.0003, min_lr=1e-6):\n",
    "        self.init_lr = tf.cast(init_lr, tf.float32)\n",
    "        self.decay_factor = tf.cast(decay_factor, tf.float32)\n",
    "        self.min_lr = tf.cast(min_lr, tf.float32)\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        lr = self.init_lr * tf.math.pow(tf.constant(1., dtype=tf.float32)/self.decay_factor, step)\n",
    "        return tf.cond(lr > self.min_lr, lambda: lr, lambda: self.min_lr)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'init_lr': self.init_lr,\n",
    "            'decay_factor': self.decay_factor,\n",
    "            'min_lr': self.min_lr,\n",
    "        }        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = ExponentialDecayGANPaper(init_lr=LEARNING_RATE, decay_factor=1.000004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MomentumAdjustor():\n",
    "    def __init__(self, init_momentum=.5, final_momentum=.7, start=1, saturate=250):\n",
    "        self.init_momentum=init_momentum\n",
    "        self.final_momentum=final_momentum\n",
    "        self.start=start\n",
    "        self.saturate=saturate\n",
    "        \n",
    "    def __call__(self, epoch):\n",
    "        eta = float(epoch - self.start) / float(self.saturate - self.start)\n",
    "        if eta < 0.:\n",
    "            eta = 0.\n",
    "        elif eta > 1.:\n",
    "            eta = 1.\n",
    "        return np.float32(self.init_momentum*(1. - eta) + eta*self.final_momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_opt = SGD(learning_rate=lr_scheduler, momentum=INIT_MOMENTUM)\n",
    "disc_opt = SGD(learning_rate=lr_scheduler, momentum=INIT_MOMENTUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_scheduler = MomentumAdjustor(INIT_MOMENTUM, final_momentum=.7, start=1, saturate=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = loss(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = loss(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return .5 * total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return loss(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puntos de control\n",
    "Acá ubicaremos donde serán gardados los puntos de control del epoch mas actual y del epoch con la mejr métrica de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = Checkpoint(gen=gen, disc=disc, gen_opt=gen_opt, disc_opt=disc_opt)\n",
    "manager_best_metric = CheckpointManager(checkpoint, directory=\"./checkpoint_mnist_model/best_metric\", max_to_keep=1)\n",
    "manager_cpkt = CheckpointManager(checkpoint, directory=\"./checkpoint_mnist_model/train_progress\", max_to_keep=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando un ciclo de entrenamiento\n",
    "A continuación crearemos un ciclo de entrenamiento dependiedo de las ocaciones que el **Discriminator** se debe actualizar ($k$) con respecto al **Generator**, recuerde que entre mayor cantidada de actualizaciones requiera `D` mas lento será el proceso de entrenamiento. en este caso se definío como $k = 1$. También haremos una función para la visualización del entrenamiento de manera cualitativa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(generator, row, col, seed = SEED):\n",
    "    latent_vector = tf.random.uniform((int(row*col),LATENT_SIZE), minval=-1.*sqrt(3.), maxval=sqrt(3.), seed=seed)\n",
    "    gen_images = generator(latent_vector, training=False)\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    \n",
    "    for i in range(int(row*col)):\n",
    "        ax = fig.add_subplot(int(row), int(col), i+1)\n",
    "        ax.imshow(tf.reshape(gen_images[i], (28,28)), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_disc_only(images):\n",
    "    noise = tf.random.uniform((images.shape[0],LATENT_SIZE), minval=-1.*sqrt(3.), maxval=sqrt(3.), seed=SEED)   \n",
    "        \n",
    "    with tf.GradientTape() as tape:\n",
    "        generate_imgs = gen(noise, training=True)\n",
    "        \n",
    "        real_output = disc(images, training=True)\n",
    "        fake_output = disc(generate_imgs, training=True)\n",
    "        \n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        \n",
    "    grads = tape.gradient(disc_loss, disc.trainable_variables)\n",
    "    disc_opt.apply_gradients(zip(grads, disc.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen_step():\n",
    "    noise = tf.random.uniform((BATCH_SIZE,LATENT_SIZE), minval=-1.*sqrt(3.), maxval=sqrt(3.), seed=SEED)   \n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generate_imgs = gen(noise, training=True)\n",
    "        \n",
    "        fake_output = disc(generate_imgs, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "\n",
    "        \n",
    "    gen_grads = gen_tape.gradient(gen_loss, gen.trainable_variables)\n",
    "    disc_grads = disc_tape.gradient(disc_loss, disc.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento\n",
    "Ahora realizaremos el entrenamiento. Tenga encuenta que en un Computador sin GPU cada epoch tomará entre 2 y 3 minutos. Puede evitar el entrenamiento cargando el punto de control en el epoch 50 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Cargar punto de control epoch 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.restore_or_initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ll = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    gen_opt.momentum.assign(momentum_scheduler(epoch+1))\n",
    "    disc_opt.momentum.assign(momentum_scheduler(epoch+1))\n",
    "    for step in tqdm(range(M // BATCH_SIZE), desc='Steps', leave=False):\n",
    "        \n",
    "        for _ in range(K):\n",
    "            images = mnist.get_next_as_optional()\n",
    "            images = images.get_value()\n",
    "            train_disc_step(images)\n",
    "        \n",
    "        train_gen_step()\n",
    "    \n",
    "    ll_mean, ll_std = ll_metric(mnist_test)\n",
    "    if max_ll < ll_mean:\n",
    "        manager_best_metric.save(checkpoint_number=epoch+1, check_interval=False)\n",
    "        max_ll = ll_mean\n",
    "    manager_cpkt.save(checkpoint_number=epoch+1)\n",
    "    display.clear_output(wait=True)\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    print(f'Log-likelihood: {ll_mean:4.2f} +/- {ll_std:4.4f}, Max ll: {max_ll:4.2f}')\n",
    "    generate_image(gen, 4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar resultados\n",
    "A continuación de manera cualitativa verificaremos si los datos generados son parecidos a los reales. Los autores usan varias métricas para esto, si tiene dudas remítase al [artículo](https://arxiv.org/pdf/1406.2661.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_image(gen, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "real_images = mnist.get_next_as_optional()\n",
    "real_images = real_images.get_value()\n",
    "real_images = real_images[:20]\n",
    "for i in range(20):\n",
    "    ax = fig.add_subplot(4, 5, i+1)\n",
    "    ax.imshow(tf.reshape(real_images[i,:], (28,28)), cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uppper_limit_noise = tf.random.uniform((LATENT_SIZE,), minval=-1.*sqrt(3.), maxval=sqrt(3.))\n",
    "# bottom_limit_noise = tf.random.uniform((LATENT_SIZE,), minval=-1.*sqrt(3.), maxval=sqrt(3.))\n",
    "\n",
    "uppper_limit_noise = sqrt(3.) * tf.ones((LATENT_SIZE,))\n",
    "bottom_limit_noise = -uppper_limit_noise\n",
    "\n",
    "generate_interp_noise = tf.linspace(bottom_limit_noise, uppper_limit_noise, 20, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,2))\n",
    "generate_interp_imgs = gen(generate_interp_noise, training=False)\n",
    "for i in range(20):\n",
    "    ax = fig.add_subplot(1, 20, i+1)\n",
    "    ax.imshow(tf.reshape(generate_interp_imgs[i], (28,28)), cmap='gray')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc(tf.ones((1,784)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc.save('disc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_dir = './discriminator_mnist/1/'\n",
    "tf.saved_model.save(disc, saved_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
